{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sesion1.ipynb","provenance":[],"collapsed_sections":["h-buZtUBtnOp","mr5GDyV93GOi","FlPM5Da224mk","ikvKjBuY6e7-","7_zMjiAbClef","AAlB-sLiUZGS"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Tutorial 1: Configuración y carga de datos en PySpark"],"metadata":{"id":"kbRRaZlBt6Nh"}},{"cell_type":"markdown","source":["##Paso 1: Configuración del entorno de PySpark en Colab"],"metadata":{"id":"K6Iv32T_kgRf"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":732},"id":"sKfMHXDwiZqF","outputId":"82930675-796a-402b-c099-37af77d01024","executionInfo":{"status":"ok","timestamp":1661909203955,"user_tz":300,"elapsed":97368,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n","Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [91.1 kB]\n","Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:12 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,938 kB]\n","Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n","Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,536 kB]\n","Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [912 kB]\n","Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,098 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,369 kB]\n","Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,076 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,313 kB]\n","Fetched 14.6 MB in 3s (4,273 kB/s)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","47 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspark\n","  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n","\u001b[K     |████████████████████████████████| 281.3 MB 44 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.5\n","  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n","\u001b[K     |████████████████████████████████| 199 kB 43.9 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=8440322015afa2df30a17b583fe45455bf151c03acf9c12fac67e90695782fc2\n","  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.5 pyspark-3.3.0\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/spark-3.2.2-bin-hadoop3.2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["#Bibliotecas para poder trabajar con Spark\n","!sudo apt update\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q https://downloads.apache.org/spark/spark-3.2.2/spark-3.2.2-bin-hadoop3.2.tgz\n","!tar xf spark-3.2.2-bin-hadoop3.2.tgz  \n","#Configuración de Spark con Python\n","!pip install -q findspark\n","!pip install pyspark\n","\n","#Estableciendo variable de entorno\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.2-bin-hadoop3.2\"\n","\n","#Buscando e inicializando la instalación de Spark\n","import findspark\n","findspark.init()\n","findspark.find()"]},{"cell_type":"markdown","source":["##Paso 2: Selección y vista de los datos"],"metadata":{"id":"3-DE0eskkyRA"}},{"cell_type":"code","source":["import pandas as pd\n","data = pd.read_csv('sample_data/california_housing_test.csv')"],"metadata":{"id":"ywqxFXoXJiv0","executionInfo":{"status":"ok","timestamp":1661910500977,"user_tz":300,"elapsed":986,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["data"],"metadata":{"id":"jH2hpm6PJYUK","colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"067c77f6-a6ba-4c48-e1f8-49f706480769","executionInfo":{"status":"ok","timestamp":1661910515186,"user_tz":300,"elapsed":168,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n","0       -122.05     37.37                27.0       3885.0           661.0   \n","1       -118.30     34.26                43.0       1510.0           310.0   \n","2       -117.81     33.78                27.0       3589.0           507.0   \n","3       -118.36     33.82                28.0         67.0            15.0   \n","4       -119.67     36.33                19.0       1241.0           244.0   \n","...         ...       ...                 ...          ...             ...   \n","2995    -119.86     34.42                23.0       1450.0           642.0   \n","2996    -118.14     34.06                27.0       5257.0          1082.0   \n","2997    -119.70     36.30                10.0        956.0           201.0   \n","2998    -117.12     34.10                40.0         96.0            14.0   \n","2999    -119.63     34.42                42.0       1765.0           263.0   \n","\n","      population  households  median_income  median_house_value  \n","0         1537.0       606.0         6.6085            344700.0  \n","1          809.0       277.0         3.5990            176500.0  \n","2         1484.0       495.0         5.7934            270500.0  \n","3           49.0        11.0         6.1359            330000.0  \n","4          850.0       237.0         2.9375             81700.0  \n","...          ...         ...            ...                 ...  \n","2995      1258.0       607.0         1.1790            225000.0  \n","2996      3496.0      1036.0         3.3906            237200.0  \n","2997       693.0       220.0         2.2895             62000.0  \n","2998        46.0        14.0         3.2708            162500.0  \n","2999       753.0       260.0         8.5608            500001.0  \n","\n","[3000 rows x 9 columns]"],"text/html":["\n","  <div id=\"df-673631e0-3c05-4d5a-a3a0-70476a22a92d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>housing_median_age</th>\n","      <th>total_rooms</th>\n","      <th>total_bedrooms</th>\n","      <th>population</th>\n","      <th>households</th>\n","      <th>median_income</th>\n","      <th>median_house_value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-122.05</td>\n","      <td>37.37</td>\n","      <td>27.0</td>\n","      <td>3885.0</td>\n","      <td>661.0</td>\n","      <td>1537.0</td>\n","      <td>606.0</td>\n","      <td>6.6085</td>\n","      <td>344700.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-118.30</td>\n","      <td>34.26</td>\n","      <td>43.0</td>\n","      <td>1510.0</td>\n","      <td>310.0</td>\n","      <td>809.0</td>\n","      <td>277.0</td>\n","      <td>3.5990</td>\n","      <td>176500.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-117.81</td>\n","      <td>33.78</td>\n","      <td>27.0</td>\n","      <td>3589.0</td>\n","      <td>507.0</td>\n","      <td>1484.0</td>\n","      <td>495.0</td>\n","      <td>5.7934</td>\n","      <td>270500.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-118.36</td>\n","      <td>33.82</td>\n","      <td>28.0</td>\n","      <td>67.0</td>\n","      <td>15.0</td>\n","      <td>49.0</td>\n","      <td>11.0</td>\n","      <td>6.1359</td>\n","      <td>330000.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-119.67</td>\n","      <td>36.33</td>\n","      <td>19.0</td>\n","      <td>1241.0</td>\n","      <td>244.0</td>\n","      <td>850.0</td>\n","      <td>237.0</td>\n","      <td>2.9375</td>\n","      <td>81700.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2995</th>\n","      <td>-119.86</td>\n","      <td>34.42</td>\n","      <td>23.0</td>\n","      <td>1450.0</td>\n","      <td>642.0</td>\n","      <td>1258.0</td>\n","      <td>607.0</td>\n","      <td>1.1790</td>\n","      <td>225000.0</td>\n","    </tr>\n","    <tr>\n","      <th>2996</th>\n","      <td>-118.14</td>\n","      <td>34.06</td>\n","      <td>27.0</td>\n","      <td>5257.0</td>\n","      <td>1082.0</td>\n","      <td>3496.0</td>\n","      <td>1036.0</td>\n","      <td>3.3906</td>\n","      <td>237200.0</td>\n","    </tr>\n","    <tr>\n","      <th>2997</th>\n","      <td>-119.70</td>\n","      <td>36.30</td>\n","      <td>10.0</td>\n","      <td>956.0</td>\n","      <td>201.0</td>\n","      <td>693.0</td>\n","      <td>220.0</td>\n","      <td>2.2895</td>\n","      <td>62000.0</td>\n","    </tr>\n","    <tr>\n","      <th>2998</th>\n","      <td>-117.12</td>\n","      <td>34.10</td>\n","      <td>40.0</td>\n","      <td>96.0</td>\n","      <td>14.0</td>\n","      <td>46.0</td>\n","      <td>14.0</td>\n","      <td>3.2708</td>\n","      <td>162500.0</td>\n","    </tr>\n","    <tr>\n","      <th>2999</th>\n","      <td>-119.63</td>\n","      <td>34.42</td>\n","      <td>42.0</td>\n","      <td>1765.0</td>\n","      <td>263.0</td>\n","      <td>753.0</td>\n","      <td>260.0</td>\n","      <td>8.5608</td>\n","      <td>500001.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3000 rows × 9 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-673631e0-3c05-4d5a-a3a0-70476a22a92d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-673631e0-3c05-4d5a-a3a0-70476a22a92d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-673631e0-3c05-4d5a-a3a0-70476a22a92d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## Paso 3: Crear la sesión de trabajo de Spark\n","\n","Ya seleccionado y visto el conjunto de datos comencemos a trabajar con PySpark. Para comenzar a trabajar con PySpark, debemos iniciar la sesión de Spark. Para esto realizaremos lo siguiente:\n","\n","\n","\n","\n","1.   Importar SparkSession \n","2.   Crear la sesión \n","\n"],"metadata":{"id":"Px0CvEobk43I"}},{"cell_type":"code","source":["#Verificar la funcionalidad de Pyspark \n","from pyspark.sql import SparkSession\n","spark_session = SparkSession.builder.appName('PySpark_prueba1').getOrCreate()\n","spark_session"],"metadata":{"id":"hqEN5b1eKRTn","colab":{"base_uri":"https://localhost:8080/","height":219},"outputId":"7e365d9b-aa67-4646-81f2-a9cc5c6856fd","executionInfo":{"status":"ok","timestamp":1661911928349,"user_tz":300,"elapsed":10222,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7ff13b1f9b50>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://d20b8a3f16cb:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.2.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySpark_prueba1</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["La SparkSession contiene los siguiente elementos:\n","\n","\n","*   Version: La versión de Spark\n","*   Master: Como estamos trabajando en un sistema en la nube pero no distribuido nos devuelve local, sin embargo, si tuvieramos un sistema distribuido aquí entonces podríamos tener diferentes clústeres, así como primero habrá un maestro y luego una estructura similar a un árbol (cluster_1, cluster_2 ... cluster_n).\n","*   AppName: Nombre de la aplicación."],"metadata":{"id":"mbRahpVtmPBu"}},{"cell_type":"markdown","source":["##Paso 4: Cargar los datos para manipularlos dentro de Spark"],"metadata":{"id":"iADBYL1_tvfU"}},{"cell_type":"code","source":["df_spark = spark_session.read.csv('sample_data/california_housing_train.csv')\n","df_spark"],"metadata":{"id":"qJdqDvH1Ke0F","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0dfcdb75-be0a-44b6-dc3b-bacf63a54827","executionInfo":{"status":"ok","timestamp":1661911986253,"user_tz":300,"elapsed":7777,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["En el caso de PySpark para visualizar los datos tenemos la función *show()* ques similar a *head()* de pandas con algunas diferencias como:\n","\n","\n","1.   Mostrar 20 registro en lugar de 5\n","2.   La apariencia de los datos\n","3.   En lugar de tomar la primera fila como encabezados la incluye como un registro y coloca _c1 a _cn como nombre de la columna.\n","\n"],"metadata":{"id":"OkNMWmBnm6QO"}},{"cell_type":"code","source":["df_spark.show()"],"metadata":{"id":"zT2_YaGFnynL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8ff16627-329a-43ed-d86b-9bcd2ffa8c86","executionInfo":{"status":"ok","timestamp":1661912086200,"user_tz":300,"elapsed":666,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n","|        _c0|      _c1|               _c2|        _c3|           _c4|        _c5|        _c6|          _c7|               _c8|\n","+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n","|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population| households|median_income|median_house_value|\n","|-114.310000|34.190000|         15.000000|5612.000000|   1283.000000|1015.000000| 472.000000|     1.493600|      66900.000000|\n","|-114.470000|34.400000|         19.000000|7650.000000|   1901.000000|1129.000000| 463.000000|     1.820000|      80100.000000|\n","|-114.560000|33.690000|         17.000000| 720.000000|    174.000000| 333.000000| 117.000000|     1.650900|      85700.000000|\n","|-114.570000|33.640000|         14.000000|1501.000000|    337.000000| 515.000000| 226.000000|     3.191700|      73400.000000|\n","|-114.570000|33.570000|         20.000000|1454.000000|    326.000000| 624.000000| 262.000000|     1.925000|      65500.000000|\n","|-114.580000|33.630000|         29.000000|1387.000000|    236.000000| 671.000000| 239.000000|     3.343800|      74000.000000|\n","|-114.580000|33.610000|         25.000000|2907.000000|    680.000000|1841.000000| 633.000000|     2.676800|      82400.000000|\n","|-114.590000|34.830000|         41.000000| 812.000000|    168.000000| 375.000000| 158.000000|     1.708300|      48500.000000|\n","|-114.590000|33.610000|         34.000000|4789.000000|   1175.000000|3134.000000|1056.000000|     2.178200|      58400.000000|\n","|-114.600000|34.830000|         46.000000|1497.000000|    309.000000| 787.000000| 271.000000|     2.190800|      48100.000000|\n","|-114.600000|33.620000|         16.000000|3741.000000|    801.000000|2434.000000| 824.000000|     2.679700|      86500.000000|\n","|-114.600000|33.600000|         21.000000|1988.000000|    483.000000|1182.000000| 437.000000|     1.625000|      62000.000000|\n","|-114.610000|34.840000|         48.000000|1291.000000|    248.000000| 580.000000| 211.000000|     2.157100|      48600.000000|\n","|-114.610000|34.830000|         31.000000|2478.000000|    464.000000|1346.000000| 479.000000|     3.212000|      70400.000000|\n","|-114.630000|32.760000|         15.000000|1448.000000|    378.000000| 949.000000| 300.000000|     0.858500|      45000.000000|\n","|-114.650000|34.890000|         17.000000|2556.000000|    587.000000|1005.000000| 401.000000|     1.699100|      69100.000000|\n","|-114.650000|33.600000|         28.000000|1678.000000|    322.000000| 666.000000| 256.000000|     2.965300|      94900.000000|\n","|-114.650000|32.790000|         21.000000|  44.000000|     33.000000|  64.000000|  27.000000|     0.857100|      25000.000000|\n","|-114.660000|32.740000|         17.000000|1388.000000|    386.000000| 775.000000| 320.000000|     1.204900|      44000.000000|\n","+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["Si queremos integrar la primera fila como los nombres de las columnas hay que agregar una opción a la hora de cargar los datos en el DataFrame."],"metadata":{"id":"xoQGO2FxmtNK"}},{"cell_type":"code","source":["#La opción option('header','true')\n","df_spark_col  = spark_session.read.option('header', 'true').csv('sample_data/california_housing_train.csv')\n","df_spark_col"],"metadata":{"id":"37zvYB-onzJt","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5203f23b-7d71-48e8-d07b-486eeb115cf6","executionInfo":{"status":"ok","timestamp":1661912130641,"user_tz":300,"elapsed":730,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[longitude: string, latitude: string, housing_median_age: string, total_rooms: string, total_bedrooms: string, population: string, households: string, median_income: string, median_house_value: string]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["df_spark_col.show()"],"metadata":{"id":"w52J4vd0oIT4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d1fe993a-928c-4cc1-b365-8e5434ff629c","executionInfo":{"status":"ok","timestamp":1661912145244,"user_tz":300,"elapsed":386,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n","|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population| households|median_income|median_house_value|\n","+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n","|-114.310000|34.190000|         15.000000|5612.000000|   1283.000000|1015.000000| 472.000000|     1.493600|      66900.000000|\n","|-114.470000|34.400000|         19.000000|7650.000000|   1901.000000|1129.000000| 463.000000|     1.820000|      80100.000000|\n","|-114.560000|33.690000|         17.000000| 720.000000|    174.000000| 333.000000| 117.000000|     1.650900|      85700.000000|\n","|-114.570000|33.640000|         14.000000|1501.000000|    337.000000| 515.000000| 226.000000|     3.191700|      73400.000000|\n","|-114.570000|33.570000|         20.000000|1454.000000|    326.000000| 624.000000| 262.000000|     1.925000|      65500.000000|\n","|-114.580000|33.630000|         29.000000|1387.000000|    236.000000| 671.000000| 239.000000|     3.343800|      74000.000000|\n","|-114.580000|33.610000|         25.000000|2907.000000|    680.000000|1841.000000| 633.000000|     2.676800|      82400.000000|\n","|-114.590000|34.830000|         41.000000| 812.000000|    168.000000| 375.000000| 158.000000|     1.708300|      48500.000000|\n","|-114.590000|33.610000|         34.000000|4789.000000|   1175.000000|3134.000000|1056.000000|     2.178200|      58400.000000|\n","|-114.600000|34.830000|         46.000000|1497.000000|    309.000000| 787.000000| 271.000000|     2.190800|      48100.000000|\n","|-114.600000|33.620000|         16.000000|3741.000000|    801.000000|2434.000000| 824.000000|     2.679700|      86500.000000|\n","|-114.600000|33.600000|         21.000000|1988.000000|    483.000000|1182.000000| 437.000000|     1.625000|      62000.000000|\n","|-114.610000|34.840000|         48.000000|1291.000000|    248.000000| 580.000000| 211.000000|     2.157100|      48600.000000|\n","|-114.610000|34.830000|         31.000000|2478.000000|    464.000000|1346.000000| 479.000000|     3.212000|      70400.000000|\n","|-114.630000|32.760000|         15.000000|1448.000000|    378.000000| 949.000000| 300.000000|     0.858500|      45000.000000|\n","|-114.650000|34.890000|         17.000000|2556.000000|    587.000000|1005.000000| 401.000000|     1.699100|      69100.000000|\n","|-114.650000|33.600000|         28.000000|1678.000000|    322.000000| 666.000000| 256.000000|     2.965300|      94900.000000|\n","|-114.650000|32.790000|         21.000000|  44.000000|     33.000000|  64.000000|  27.000000|     0.857100|      25000.000000|\n","|-114.660000|32.740000|         17.000000|1388.000000|    386.000000| 775.000000| 320.000000|     1.204900|      44000.000000|\n","|-114.670000|33.920000|         17.000000|  97.000000|     24.000000|  29.000000|  15.000000|     1.265600|      27500.000000|\n","+-----------+---------+------------------+-----------+--------------+-----------+-----------+-------------+------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["Como comparativa entre Pandas y PySpark ambos manejan la información dentro de DataFrames pero la función *show()* solo es aplicable en Spark mientras que *head()* funciona en ambos"],"metadata":{"id":"SkGw3U3UpiD7"}},{"cell_type":"code","source":["print(type(df_spark_col))\n","print(type(data))"],"metadata":{"id":"OBoQNiUVoSD4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"509a5b88-9459-4177-a1e5-27541d5a7ea4","executionInfo":{"status":"ok","timestamp":1661912179459,"user_tz":300,"elapsed":181,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pyspark.sql.dataframe.DataFrame'>\n","<class 'pandas.core.frame.DataFrame'>\n"]}]},{"cell_type":"markdown","source":["La función *head()* muestra por cada columna el valor que tiene, sin embargo muestra la información por fila utilizando este formato mencionado"],"metadata":{"id":"M4l2FDVMqRI3"}},{"cell_type":"code","source":["df_spark_col.head(10)"],"metadata":{"id":"B2FAh9QDoha_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"eb052f73-8e74-415c-a100-867472c56629","executionInfo":{"status":"ok","timestamp":1661912198437,"user_tz":300,"elapsed":527,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(longitude='-114.310000', latitude='34.190000', housing_median_age='15.000000', total_rooms='5612.000000', total_bedrooms='1283.000000', population='1015.000000', households='472.000000', median_income='1.493600', median_house_value='66900.000000'),\n"," Row(longitude='-114.470000', latitude='34.400000', housing_median_age='19.000000', total_rooms='7650.000000', total_bedrooms='1901.000000', population='1129.000000', households='463.000000', median_income='1.820000', median_house_value='80100.000000'),\n"," Row(longitude='-114.560000', latitude='33.690000', housing_median_age='17.000000', total_rooms='720.000000', total_bedrooms='174.000000', population='333.000000', households='117.000000', median_income='1.650900', median_house_value='85700.000000'),\n"," Row(longitude='-114.570000', latitude='33.640000', housing_median_age='14.000000', total_rooms='1501.000000', total_bedrooms='337.000000', population='515.000000', households='226.000000', median_income='3.191700', median_house_value='73400.000000'),\n"," Row(longitude='-114.570000', latitude='33.570000', housing_median_age='20.000000', total_rooms='1454.000000', total_bedrooms='326.000000', population='624.000000', households='262.000000', median_income='1.925000', median_house_value='65500.000000'),\n"," Row(longitude='-114.580000', latitude='33.630000', housing_median_age='29.000000', total_rooms='1387.000000', total_bedrooms='236.000000', population='671.000000', households='239.000000', median_income='3.343800', median_house_value='74000.000000'),\n"," Row(longitude='-114.580000', latitude='33.610000', housing_median_age='25.000000', total_rooms='2907.000000', total_bedrooms='680.000000', population='1841.000000', households='633.000000', median_income='2.676800', median_house_value='82400.000000'),\n"," Row(longitude='-114.590000', latitude='34.830000', housing_median_age='41.000000', total_rooms='812.000000', total_bedrooms='168.000000', population='375.000000', households='158.000000', median_income='1.708300', median_house_value='48500.000000'),\n"," Row(longitude='-114.590000', latitude='33.610000', housing_median_age='34.000000', total_rooms='4789.000000', total_bedrooms='1175.000000', population='3134.000000', households='1056.000000', median_income='2.178200', median_house_value='58400.000000'),\n"," Row(longitude='-114.600000', latitude='34.830000', housing_median_age='46.000000', total_rooms='1497.000000', total_bedrooms='309.000000', population='787.000000', households='271.000000', median_income='2.190800', median_house_value='48100.000000')]"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["Si queremos saber información acerca de los datos utilizamos la función *printSchema()* la cual muestra el nombre de cada columna, su tipo de dato y si permite valores nulos"],"metadata":{"id":"4tNzS6dPrfns"}},{"cell_type":"code","source":["df_spark_col.printSchema()"],"metadata":{"id":"_bdNEtSRokEQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba88c9ab-aa6d-4276-9990-cdda2960ff53","executionInfo":{"status":"ok","timestamp":1661912304994,"user_tz":300,"elapsed":205,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- longitude: string (nullable = true)\n"," |-- latitude: string (nullable = true)\n"," |-- housing_median_age: string (nullable = true)\n"," |-- total_rooms: string (nullable = true)\n"," |-- total_bedrooms: string (nullable = true)\n"," |-- population: string (nullable = true)\n"," |-- households: string (nullable = true)\n"," |-- median_income: string (nullable = true)\n"," |-- median_house_value: string (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["# Tutorial: Valores nulos"],"metadata":{"id":"OKRCyfLxFjLm"}},{"cell_type":"code","source":["#Creamos una sesión de PySpark\n","from pyspark.sql import SparkSession\n","\n","null_spark = SparkSession.builder.appName('ValoresNulos').getOrCreate()\n","null_spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"rM7OFEeUFo3q","executionInfo":{"status":"ok","timestamp":1661912379195,"user_tz":300,"elapsed":177,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}},"outputId":"6fdd08e5-f1dd-4cb6-fed8-5b4cb4fa13e6"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7ff13b1f9b50>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://d20b8a3f16cb:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.2.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySpark_prueba1</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["#Cargamos los datos dentro de un DataFrame de la sesión\n","df_null_pyspark = null_spark.read.csv('part2.csv', header = True, inferSchema = True)\n","df_null_pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hehcKKUYFsVU","executionInfo":{"status":"ok","timestamp":1661912456054,"user_tz":300,"elapsed":772,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}},"outputId":"71bb395b-d8ab-4441-c3cf-342c70d3c815"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[Employee Name: string, Age of Employee: int, Experience (in years): int, Salary (per month - $): int]"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["#Visualizamos la información\n","df_null_pyspark.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TwKaACbcGCK3","executionInfo":{"status":"ok","timestamp":1661912531371,"user_tz":300,"elapsed":777,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}},"outputId":"9d29cd03-e19c-4805-e2b2-3906762f4f5c"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","|        Oscar|           null|                 null|                 40000|\n","|         null|             34|                   10|                 38000|\n","|         null|             36|                 null|                  null|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"code","source":["# Nuevamente vemos la estructura de la información\n","# recordando que cuando tenemos nullable = true significa que esa columna permite \n","# valores nulos\n","df_null_pyspark.printSchema()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORvmLGGPGE2i","executionInfo":{"status":"ok","timestamp":1661912549305,"user_tz":300,"elapsed":268,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}},"outputId":"4118022a-880c-403c-f4b4-676d7247a909"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- Employee Name: string (nullable = true)\n"," |-- Age of Employee: integer (nullable = true)\n"," |-- Experience (in years): integer (nullable = true)\n"," |-- Salary (per month - $): integer (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["El función para eliminar los valores nulos dentro de la información es na.drop(). Esta función elimina completamente los registros que tiene algún valor nulo."],"metadata":{"id":"C3u6V9QsGHHw"}},{"cell_type":"code","source":["df_null_pyspark.na.drop().show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LaZCw7L_GH6h","executionInfo":{"status":"ok","timestamp":1661912568422,"user_tz":300,"elapsed":450,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}},"outputId":"8019f127-4d33-4a4a-cd00-9c62de23e79f"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Si queremos controlar el como se eliminan los registros la función tiene un parámetro llamado *how* con dos posibles valores:\n","\n","\n","*   ALL: Elimina la tupla siempre y cuando todos los valores asociados a cada columna sean nulos.\n","*   ANY: Elimina la tupla si alguno de los valores asociados a cada columns es nulo. Esta es la configuración por default."],"metadata":{"id":"JI4rXQWBGMc0"}},{"cell_type":"code","source":["df_null_pyspark.na.drop(how=\"all\").show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YE1z--FBGNy0","executionInfo":{"status":"ok","timestamp":1661912619969,"user_tz":300,"elapsed":412,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}},"outputId":"59553f78-aa25-433b-a0cb-320a55252102"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","|        Oscar|           null|                 null|                 40000|\n","|         null|             34|                   10|                 38000|\n","|         null|             36|                 null|                  null|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"code","source":["df_null_pyspark.na.drop(how=\"any\").show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7qA9cjvGRpO","executionInfo":{"status":"ok","timestamp":1661912654609,"user_tz":300,"elapsed":406,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}},"outputId":"601af53d-ef18-49d5-c1e2-d009b27ced56"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Tambien hay forma de especificar el número mínimo de valores nulos aceptables con el parámetro thresh. En el ejemplo se puede observar que elimina solo una tupla que tenia tres valores nulos asociados."],"metadata":{"id":"tlkjJTTHGUVC"}},{"cell_type":"code","source":["df_null_pyspark.na.drop(thresh=2).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVTyMoKsGVJ0","executionInfo":{"status":"ok","timestamp":1661912686716,"user_tz":300,"elapsed":487,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}},"outputId":"8ba3a248-6760-4fb9-edd8-2ae4c15a1093"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","|        Oscar|           null|                 null|                 40000|\n","|         null|             34|                   10|                 38000|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"markdown","source":["De igual forma podemos combiar el parámetro how con subset para indicarle las columnas donde nos interesan detectar valores nulos en las tuplas y eliminarlas."],"metadata":{"id":"h2rV-UuLGY_n"}},{"cell_type":"code","source":["df_null_pyspark.na.drop(how='any', subset=['Experience (in years)']).show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eVwEDeTJGZp4","executionInfo":{"status":"ok","timestamp":1661912712965,"user_tz":300,"elapsed":507,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}},"outputId":"e8a4bb9e-ca2f-4819-c6fb-7d74e64e5616"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","|         null|             34|                   10|                 38000|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Podemos rellenar los valores nulos con algún valor en especifico utilizando la función na.fill() indicando el valor y la columna."],"metadata":{"id":"7YYReA3PGcKU"}},{"cell_type":"code","source":["df_null_pyspark.na.fill('NA values', 'Employee Name').show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VAKyWNSwGcbM","executionInfo":{"status":"ok","timestamp":1661912737559,"user_tz":300,"elapsed":555,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}},"outputId":"4d8a46ba-838d-4089-ffdc-b59d16bf7039"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","|        Oscar|           null|                 null|                 40000|\n","|    NA values|             34|                   10|                 38000|\n","|    NA values|             36|                 null|                  null|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Otra alternativa para rellenar los valores faltantes es utilizando el método de imputación de datos utilizando la media. Para esto hay que utilizar la clase Imputer especificando las columnas de entrada y las de salida que se agregaran al DataFrame así como la estrategia en este caso utilizar la media. Después, se utiliza la función fit() y transform() para integrar las columnas imputadas."],"metadata":{"id":"T9h3cQrsGiTK"}},{"cell_type":"code","source":["from pyspark.ml.feature import Imputer\n","\n","imputer = Imputer(\n","    inputCols = ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)'],\n","    outputCols = [\"{}_imputed\".format(a) for a in ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)']]\n",").setStrategy(\"mean\")\n","imputer.fit(df_null_pyspark).transform(df_null_pyspark).show()"],"metadata":{"id":"JrZTEoaGGjvd","executionInfo":{"status":"ok","timestamp":1661912754671,"user_tz":300,"elapsed":2244,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}},"outputId":"6034ab42-cc0b-4e2a-e9ec-0f1e4f51295c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|Age of Employee_imputed|Experience (in years)_imputed|Salary (per month - $)_imputed|\n","+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n","|       Oliver|             31|                   10|                 30000|                     31|                           10|                         30000|\n","|        Harry|             30|                    8|                 25000|                     30|                            8|                         25000|\n","|       George|             29|                    4|                 20000|                     29|                            4|                         20000|\n","|         Jack|             24|                    3|                 20000|                     24|                            3|                         20000|\n","|        Jacob|             21|                    1|                 15000|                     21|                            1|                         15000|\n","|          Leo|             23|                    2|                 18000|                     23|                            2|                         18000|\n","|        Oscar|           null|                 null|                 40000|                     28|                            5|                         40000|\n","|         null|             34|                   10|                 38000|                     34|                           10|                         38000|\n","|         null|             36|                 null|                  null|                     36|                            5|                         25750|\n","+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["#Tutorial 2: Consultas en DataFrame dentro de PySpark "],"metadata":{"id":"h-buZtUBtnOp"}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName('OperacionesFiltrado').getOrCreate()\n","spark"],"metadata":{"id":"tgvc4GJCqYPD","colab":{"base_uri":"https://localhost:8080/","height":219},"outputId":"b0fe713a-b94b-4dd5-aed2-9a6bbd8d37cc","executionInfo":{"status":"ok","timestamp":1661912893844,"user_tz":300,"elapsed":187,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7ff13b1f9b50>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://d20b8a3f16cb:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.2.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySpark_prueba1</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["Para cargar la información usaremos solamente la función *csv()* pero agregando parámetros de configuración para que tome el primer registro como los nombres de las columnas y tambien que a partir de los datos de entrada infiera el tipo de dato. Si no colocamos esto automáticamente considera de tipo *string* las columnas."],"metadata":{"id":"Xa09MN6CwPEq"}},{"cell_type":"code","source":["df_filter_pyspark = spark.read.csv('part2.csv', header = True, inferSchema=True)\n","df_filter_pyspark.show()"],"metadata":{"id":"n87v4tRhqpZe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"064a71eb-7c92-4c8a-8a2e-55e2cb8095be","executionInfo":{"status":"ok","timestamp":1661912900228,"user_tz":300,"elapsed":637,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","|        Oscar|           null|                 null|                 40000|\n","|         null|             34|                   10|                 38000|\n","|         null|             36|                 null|                  null|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"code","source":["df_filter_pyspark.printSchema()"],"metadata":{"id":"4neGDBsyvX-j","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1ca0ca64-c8c7-45a2-e8a7-1fdb50f99fc4","executionInfo":{"status":"ok","timestamp":1661912910404,"user_tz":300,"elapsed":173,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- Employee Name: string (nullable = true)\n"," |-- Age of Employee: integer (nullable = true)\n"," |-- Experience (in years): integer (nullable = true)\n"," |-- Salary (per month - $): integer (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["Si se necesita podemos renombrar las columnas para referirnos a ellas de una forma más sencilla o simplificada con la función *withColumnRenamed()*."],"metadata":{"id":"uWV3LXYuw0IQ"}},{"cell_type":"markdown","source":["## Filtros y selección"],"metadata":{"id":"mr5GDyV93GOi"}},{"cell_type":"code","source":["df_filter_pyspark= df_filter_pyspark.withColumnRenamed(\"Salary (per month - $)\",\"EmpSalary\")\n","df_filter_pyspark.show()"],"metadata":{"id":"_B5aqNbGrK_2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4851420e-7a01-4f04-c58c-6f2b3269268f","executionInfo":{"status":"ok","timestamp":1661912941689,"user_tz":300,"elapsed":377,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+---------+\n","|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n","+-------------+---------------+---------------------+---------+\n","|       Oliver|             31|                   10|    30000|\n","|        Harry|             30|                    8|    25000|\n","|       George|             29|                    4|    20000|\n","|         Jack|             24|                    3|    20000|\n","|        Jacob|             21|                    1|    15000|\n","|          Leo|             23|                    2|    18000|\n","|        Oscar|           null|                 null|    40000|\n","|         null|             34|                   10|    38000|\n","|         null|             36|                 null|     null|\n","+-------------+---------------+---------------------+---------+\n","\n"]}]},{"cell_type":"markdown","source":["\n","La función *filter()* nos permite filtrar la información a través de condiciones. Por ejemplo, vamos a mostrar unicamente aquellos empleados que tengan un salario menor o igual a $25,000.00."],"metadata":{"id":"fUV8l1eWy90u"}},{"cell_type":"code","source":["df_filter_pyspark.filter(\"EmpSalary<=25000\").show()"],"metadata":{"id":"FGGtrHVxq1qB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"16b2a3fe-afe3-4e70-8090-85f058c6f898","executionInfo":{"status":"ok","timestamp":1661912959119,"user_tz":300,"elapsed":406,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+---------+\n","|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n","+-------------+---------------+---------------------+---------+\n","|        Harry|             30|                    8|    25000|\n","|       George|             29|                    4|    20000|\n","|         Jack|             24|                    3|    20000|\n","|        Jacob|             21|                    1|    15000|\n","|          Leo|             23|                    2|    18000|\n","+-------------+---------------+---------------------+---------+\n","\n"]}]},{"cell_type":"markdown","source":["Como pudieron observar hay una cierta similitud de la función *filter()* con SELECT de SQL. Es por eso que se pueden utilizar consultas SQL y tratar los DataFrames como tablas o vistas de un modelo relacional. La función *createOrReplaceTempView()* registra el DataFrame como una vista temporal dentro de la sesión que puede ejecutar consutlas SQL."],"metadata":{"id":"gO6txvqVzdZL"}},{"cell_type":"code","source":["df_filter_pyspark.createOrReplaceTempView(\"empleados\")\n","sqlDF = spark.sql(\"SELECT * FROM empleados\")\n","sqlDF.show()"],"metadata":{"id":"CSkcljBNxiKE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f00d2416-a3c5-45d2-fdbb-11442c84afe1","executionInfo":{"status":"ok","timestamp":1661913062124,"user_tz":300,"elapsed":392,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+---------+\n","|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n","+-------------+---------------+---------------------+---------+\n","|       Oliver|             31|                   10|    30000|\n","|        Harry|             30|                    8|    25000|\n","|       George|             29|                    4|    20000|\n","|         Jack|             24|                    3|    20000|\n","|        Jacob|             21|                    1|    15000|\n","|          Leo|             23|                    2|    18000|\n","|        Oscar|           null|                 null|    40000|\n","|         null|             34|                   10|    38000|\n","|         null|             36|                 null|     null|\n","+-------------+---------------+---------------------+---------+\n","\n"]}]},{"cell_type":"markdown","source":["Si la vista temporal que se produce quieren que sea utilizada en multiples sesiones entonces hay que utilizar la función *createOrReplaceTempView()*. El unico detalle es que la vista quedará anclada a una base de datos llamada *global_temp*."],"metadata":{"id":"_4UHtcD20q8i"}},{"cell_type":"code","source":["df_filter_pyspark.createGlobalTempView(\"g_empleados\")\n","sqlDF = spark.sql(\"SELECT * FROM global_temp.g_empleados\")\n","sqlDF.show()"],"metadata":{"id":"oNc4FMzG1Rln","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6693eb6b-c77c-4140-d44c-cd0dfe74f02a","executionInfo":{"status":"ok","timestamp":1661913105730,"user_tz":300,"elapsed":565,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+---------+\n","|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n","+-------------+---------------+---------------------+---------+\n","|       Oliver|             31|                   10|    30000|\n","|        Harry|             30|                    8|    25000|\n","|       George|             29|                    4|    20000|\n","|         Jack|             24|                    3|    20000|\n","|        Jacob|             21|                    1|    15000|\n","|          Leo|             23|                    2|    18000|\n","|        Oscar|           null|                 null|    40000|\n","|         null|             34|                   10|    38000|\n","|         null|             36|                 null|     null|\n","+-------------+---------------+---------------------+---------+\n","\n"]}]},{"cell_type":"markdown","source":["Como mencionamos la vista perdura en otras sesiones."],"metadata":{"id":"6ATcN_3S1162"}},{"cell_type":"code","source":["spark.newSession().sql(\"SELECT * FROM global_temp.g_empleados\").show()"],"metadata":{"id":"cR9qBGWh1-rz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ce95b812-aa93-4c77-9bce-d0b41671e45f","executionInfo":{"status":"ok","timestamp":1661913141924,"user_tz":300,"elapsed":363,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+---------+\n","|Employee Name|Age of Employee|Experience (in years)|EmpSalary|\n","+-------------+---------------+---------------------+---------+\n","|       Oliver|             31|                   10|    30000|\n","|        Harry|             30|                    8|    25000|\n","|       George|             29|                    4|    20000|\n","|         Jack|             24|                    3|    20000|\n","|        Jacob|             21|                    1|    15000|\n","|          Leo|             23|                    2|    18000|\n","|        Oscar|           null|                 null|    40000|\n","|         null|             34|                   10|    38000|\n","|         null|             36|                 null|     null|\n","+-------------+---------------+---------------------+---------+\n","\n"]}]},{"cell_type":"markdown","source":["Se puede de igual forma cambiar el nombre de multiples columnas al mismo tiempo."],"metadata":{"id":"lOw7X7R92H1a"}},{"cell_type":"code","source":["#Cambiamos el nombre de multiples columnas \n","df_filter_pyspark= df_filter_pyspark.withColumnRenamed(\"Age of Employee\",\"EmpAge\").withColumnRenamed(\"Employee Name\",\"EmpName\")\n","df_filter_pyspark.show()"],"metadata":{"id":"_vkSgApfrlzG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"92188d3f-4bc3-4ed5-dee1-19c3b597a76b","executionInfo":{"status":"ok","timestamp":1661913182588,"user_tz":300,"elapsed":344,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+------+---------------------+---------+\n","|EmpName|EmpAge|Experience (in years)|EmpSalary|\n","+-------+------+---------------------+---------+\n","| Oliver|    31|                   10|    30000|\n","|  Harry|    30|                    8|    25000|\n","| George|    29|                    4|    20000|\n","|   Jack|    24|                    3|    20000|\n","|  Jacob|    21|                    1|    15000|\n","|    Leo|    23|                    2|    18000|\n","|  Oscar|  null|                 null|    40000|\n","|   null|    34|                   10|    38000|\n","|   null|    36|                 null|     null|\n","+-------+------+---------------------+---------+\n","\n"]}]},{"cell_type":"markdown","source":["Al igual que en SQL se pueden seleccionar las columnas que serán mostradas dentro de la consulta acompañando a la función *filter()* con la función *select()*."],"metadata":{"id":"73Rl2uG32Q_Z"}},{"cell_type":"code","source":["df_filter_pyspark.filter(\"EmpSalary<=25000\").select(['EmpName','EmpAge']).show()"],"metadata":{"id":"tGtFqXeyri3Z","colab":{"base_uri":"https://localhost:8080/"},"outputId":"703443a1-13f1-4c7e-8150-6ac2951e3b18","executionInfo":{"status":"ok","timestamp":1661913211056,"user_tz":300,"elapsed":412,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+------+\n","|EmpName|EmpAge|\n","+-------+------+\n","|  Harry|    30|\n","| George|    29|\n","|   Jack|    24|\n","|  Jacob|    21|\n","|    Leo|    23|\n","+-------+------+\n","\n"]}]},{"cell_type":"markdown","source":["Otra manera de filtrar la información de los registros es utilizar un estilo similar a Pandas."],"metadata":{"id":"NXx1CwoD2sW1"}},{"cell_type":"code","source":["df_filter_pyspark.filter(df_filter_pyspark['EmpSalary']<=25000).select(['EmpName','EmpAge']).show()"],"metadata":{"id":"LOZuURvRr4HZ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cb9c0aed-f64a-4b4c-e302-ebd45e934d11","executionInfo":{"status":"ok","timestamp":1661913231057,"user_tz":300,"elapsed":340,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+------+\n","|EmpName|EmpAge|\n","+-------+------+\n","|  Harry|    30|\n","| George|    29|\n","|   Jack|    24|\n","|  Jacob|    21|\n","|    Leo|    23|\n","+-------+------+\n","\n"]}]},{"cell_type":"markdown","source":["## Operadores Lógicos"],"metadata":{"id":"FlPM5Da224mk"}},{"cell_type":"markdown","source":["Los operadores lógicos disponibles son AND (&), OR (|) y NOT (~)."],"metadata":{"id":"pHT4extP4NfO"}},{"cell_type":"markdown","source":["Ejemplo con AND: Los empleados que su salario sea menor o igual a \\$30,000.00 y que sea mayor o igual a \\$18,000.00."],"metadata":{"id":"gOTdAcq64fFd"}},{"cell_type":"code","source":["df_filter_pyspark.filter((df_filter_pyspark['EmpSalary']<=30000)\n","                          & (df_filter_pyspark['EmpSalary']>=18000)).show()"],"metadata":{"id":"vYgWyHBUsDw-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"78609591-8341-4aae-822c-090d52ed0661","executionInfo":{"status":"ok","timestamp":1661913303875,"user_tz":300,"elapsed":336,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+------+---------------------+---------+\n","|EmpName|EmpAge|Experience (in years)|EmpSalary|\n","+-------+------+---------------------+---------+\n","| Oliver|    31|                   10|    30000|\n","|  Harry|    30|                    8|    25000|\n","| George|    29|                    4|    20000|\n","|   Jack|    24|                    3|    20000|\n","|    Leo|    23|                    2|    18000|\n","+-------+------+---------------------+---------+\n","\n"]}]},{"cell_type":"code","source":["#Cambiamos el nombre de la columna experiencia\n","df_filter_pyspark= df_filter_pyspark.withColumnRenamed(\"Experience (in years)\",\"EmpExperience\")\n","df_filter_pyspark.show()"],"metadata":{"id":"FjuqaJ80syOs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"60bfaa6b-4898-4281-f159-e36c353e78f8","executionInfo":{"status":"ok","timestamp":1661913314594,"user_tz":300,"elapsed":367,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+------+-------------+---------+\n","|EmpName|EmpAge|EmpExperience|EmpSalary|\n","+-------+------+-------------+---------+\n","| Oliver|    31|           10|    30000|\n","|  Harry|    30|            8|    25000|\n","| George|    29|            4|    20000|\n","|   Jack|    24|            3|    20000|\n","|  Jacob|    21|            1|    15000|\n","|    Leo|    23|            2|    18000|\n","|  Oscar|  null|         null|    40000|\n","|   null|    34|           10|    38000|\n","|   null|    36|         null|     null|\n","+-------+------+-------------+---------+\n","\n"]}]},{"cell_type":"markdown","source":["Ejemplo con OR: Los empleados que su salario sea menor o igual a \\$30,000.00 ó que su experiencia laboral sea mayor o igual a 3 años."],"metadata":{"id":"latXscc144pR"}},{"cell_type":"code","source":["df_filter_pyspark.filter((df_filter_pyspark['EmpSalary']<=30000)\n","                          | (df_filter_pyspark['EmpExperience']>=3)).show()"],"metadata":{"id":"WxIIaEmvsvvA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cfac640c-f7a4-47e3-d49f-9912f815b7d1","executionInfo":{"status":"ok","timestamp":1661913320785,"user_tz":300,"elapsed":389,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+------+-------------+---------+\n","|EmpName|EmpAge|EmpExperience|EmpSalary|\n","+-------+------+-------------+---------+\n","| Oliver|    31|           10|    30000|\n","|  Harry|    30|            8|    25000|\n","| George|    29|            4|    20000|\n","|   Jack|    24|            3|    20000|\n","|  Jacob|    21|            1|    15000|\n","|    Leo|    23|            2|    18000|\n","|   null|    34|           10|    38000|\n","+-------+------+-------------+---------+\n","\n"]}]},{"cell_type":"markdown","source":["Ejemplo NOT: Los empleandos que su edad no sea mayor o igual a 30 años."],"metadata":{"id":"WFxPQ4OL5YIR"}},{"cell_type":"code","source":["df_filter_pyspark.filter(~(df_filter_pyspark['EmpAge']>=30)).show()"],"metadata":{"id":"ohEM94QPs9UE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7a996487-d013-4dc1-d658-d7552343e53f","executionInfo":{"status":"ok","timestamp":1661913333948,"user_tz":300,"elapsed":403,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+------+-------------+---------+\n","|EmpName|EmpAge|EmpExperience|EmpSalary|\n","+-------+------+-------------+---------+\n","| George|    29|            4|    20000|\n","|   Jack|    24|            3|    20000|\n","|  Jacob|    21|            1|    15000|\n","|    Leo|    23|            2|    18000|\n","+-------+------+-------------+---------+\n","\n"]}]},{"cell_type":"code","source":["#Creamos una sesión de PySpark\n","from pyspark.sql import SparkSession\n","\n","null_spark = SparkSession.builder.appName('ValoresNulos').getOrCreate()\n","null_spark"],"metadata":{"id":"2WFOahsM6utd","colab":{"base_uri":"https://localhost:8080/","height":219},"outputId":"3e445947-5579-4702-9ade-283dbd03bad9","executionInfo":{"status":"ok","timestamp":1661913378782,"user_tz":300,"elapsed":5,"user":{"displayName":"Víctor Adrián Sosa Hernández","userId":"18028332315834445711"}}},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7ff13b1f9b50>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://d20b8a3f16cb:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.2.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySpark_prueba1</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["#Cargamos los datos dentro de un DataFrame de la sesión\n","df_null_pyspark = null_spark.read.csv('part2.csv', header = True, inferSchema = True)\n","df_null_pyspark"],"metadata":{"id":"O5TJdLAp7ASc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fab7a200-9514-4672-ac98-4ce5148d28de"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[Employee Name: string, Age of Employee: int, Experience (in years): int, Salary (per month - $): int]"]},"metadata":{},"execution_count":36}]},{"cell_type":"code","source":["#Visualizamos la información\n","df_null_pyspark.show()"],"metadata":{"id":"8NXstlu57QSQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fa766a86-d49b-4db4-ac1d-0fd92765ea87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","|        Oscar|           null|                 null|                 40000|\n","|         null|             34|                   10|                 38000|\n","|         null|             36|                 null|                  null|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"code","source":["# Nuevamente vemos la estructura de la información\n","# recordando que cuando tenemos nullable = true significa que esa columna permite \n","# valores nulos\n","df_null_pyspark.printSchema()"],"metadata":{"id":"eAflsQi47elO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"549d89fa-9033-4011-c9d2-4b9335e13d50"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- Employee Name: string (nullable = true)\n"," |-- Age of Employee: integer (nullable = true)\n"," |-- Experience (in years): integer (nullable = true)\n"," |-- Salary (per month - $): integer (nullable = true)\n","\n"]}]},{"cell_type":"markdown","source":["El función para eliminar los valores nulos dentro de la información es *na.drop()*. Esta función elimina completamente los registros que tiene algún valor nulo.\n","\n"],"metadata":{"id":"KPVY4QKT728z"}},{"cell_type":"code","source":["df_null_pyspark.na.drop().show()"],"metadata":{"id":"Nk7qANkD72Z4","colab":{"base_uri":"https://localhost:8080/"},"outputId":"483a4994-b48e-41cb-ef4e-e82e0cda61c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Si queremos controlar el como se eliminan los registros la función tiene un parámetro llamado *how* con dos posibles valores:\n","\n","\n","*   ALL: Elimina la tupla siempre y cuando todos los valores asociados a cada columna sean nulos.\n","*   ANY: Elimina la tupla si alguno de los valores asociados a cada columns es nulo. Esta es la configuración por default.\n","\n"],"metadata":{"id":"HULRD2Mr8WUI"}},{"cell_type":"code","source":["df_null_pyspark.na.drop(how=\"all\").show()"],"metadata":{"id":"KI5INUDi9DCE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"81257c44-d502-40ff-a00c-c443a48b2354"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","|        Oscar|           null|                 null|                 40000|\n","|         null|             34|                   10|                 38000|\n","|         null|             36|                 null|                  null|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"code","source":["df_null_pyspark.na.drop(how=\"any\").show()"],"metadata":{"id":"M7EqNcvQ9G02","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c81c3193-500d-415f-fed4-a84133661c11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Tambien hay forma de especificar el número mínimo de valores nulos aceptables con el parámetro *thresh*. En el ejemplo se puede observar que elimina solo una tupla que tenia tres valores nulos asociados."],"metadata":{"id":"6-m7EXqo9L8f"}},{"cell_type":"code","source":["df_null_pyspark.na.drop(thresh=2).show()"],"metadata":{"id":"QEZfXpS49XDo","colab":{"base_uri":"https://localhost:8080/"},"outputId":"63bb23d1-b40e-4661-ad74-71fb6388f10d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","|        Oscar|           null|                 null|                 40000|\n","|         null|             34|                   10|                 38000|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"markdown","source":["De igual forma podemos combiar el parámetro *how* con *subset* para indicarle las columnas donde nos interesan detectar valores nulos en las tuplas y eliminarlas."],"metadata":{"id":"HKMI4Qmc9yji"}},{"cell_type":"code","source":["df_null_pyspark.na.drop(how='any', subset=['Experience (in years)']).show()"],"metadata":{"id":"lhma9LrN9ya0","colab":{"base_uri":"https://localhost:8080/"},"outputId":"59dc4e94-d42b-44b7-d060-b191821c4c83"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","|         null|             34|                   10|                 38000|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Podemos rellenar los valores nulos con algún valor en especifico utilizando la función *na.fill()* indicando el valor y la columna."],"metadata":{"id":"SKkz--0i-Oyk"}},{"cell_type":"code","source":["df_null_pyspark.na.fill('NA values', 'Employee Name').show()"],"metadata":{"id":"IAMqYGjo-krE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6cd472c6-5a32-4172-c67b-868c735a76a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|\n","+-------------+---------------+---------------------+----------------------+\n","|       Oliver|             31|                   10|                 30000|\n","|        Harry|             30|                    8|                 25000|\n","|       George|             29|                    4|                 20000|\n","|         Jack|             24|                    3|                 20000|\n","|        Jacob|             21|                    1|                 15000|\n","|          Leo|             23|                    2|                 18000|\n","|        Oscar|           null|                 null|                 40000|\n","|    NA values|             34|                   10|                 38000|\n","|    NA values|             36|                 null|                  null|\n","+-------------+---------------+---------------------+----------------------+\n","\n"]}]},{"cell_type":"markdown","source":["Otra alternativa para rellenar los valores faltantes es utilizando el método de imputación de datos utilizando la media. Para esto hay que utilizar la clase *Imputer* especificando las columnas de entrada y las de salida que se agregaran al DataFrame así como la estrategia en este caso utilizar la media. Después, se utiliza la función *fit()* y *transform()* para integrar las columnas imputadas."],"metadata":{"id":"GbXa3gu6-u4i"}},{"cell_type":"code","source":["from pyspark.ml.feature import Imputer\n","\n","imputer = Imputer(\n","    inputCols = ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)'],\n","    outputCols = [\"{}_imputed\".format(a) for a in ['Age of Employee', 'Experience (in years)', 'Salary (per month - $)']]\n",").setStrategy(\"mean\")\n","imputer.fit(df_null_pyspark).transform(df_null_pyspark).show()"],"metadata":{"id":"8FAlh9Sy-vBv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5700c9ea-6e60-4e00-e598-d536f7a6721a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n","|Employee Name|Age of Employee|Experience (in years)|Salary (per month - $)|Age of Employee_imputed|Experience (in years)_imputed|Salary (per month - $)_imputed|\n","+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n","|       Oliver|             31|                   10|                 30000|                     31|                           10|                         30000|\n","|        Harry|             30|                    8|                 25000|                     30|                            8|                         25000|\n","|       George|             29|                    4|                 20000|                     29|                            4|                         20000|\n","|         Jack|             24|                    3|                 20000|                     24|                            3|                         20000|\n","|        Jacob|             21|                    1|                 15000|                     21|                            1|                         15000|\n","|          Leo|             23|                    2|                 18000|                     23|                            2|                         18000|\n","|        Oscar|           null|                 null|                 40000|                     28|                            5|                         40000|\n","|         null|             34|                   10|                 38000|                     34|                           10|                         38000|\n","|         null|             36|                 null|                  null|                     36|                            5|                         25750|\n","+-------------+---------------+---------------------+----------------------+-----------------------+-----------------------------+------------------------------+\n","\n"]}]},{"cell_type":"markdown","source":["# Tutorial 3: Manejo de DataFrames en PySpark"],"metadata":{"id":"7_zMjiAbClef"}},{"cell_type":"code","source":["#Creamos la sesión de trabajo\n","from pyspark.sql import SparkSession\n","data_spark = SparkSession.builder.appName('DataFrame_article').getOrCreate()\n","data_spark"],"metadata":{"id":"gWBdsz42Czua","colab":{"base_uri":"https://localhost:8080/","height":219},"outputId":"6d98f4f4-fb5a-43b3-be3f-4202107d6cf9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7f2405a80310>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://a9cb84e4df70:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.2.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySpark_prueba1</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["#Cargamos los datos e imprimimos la descripción del schema\n","df_pyspark = data_spark.read.option('header','true').csv('/content/sample_data/california_housing_train.csv', inferSchema=True)\n","df_pyspark.printSchema()"],"metadata":{"id":"4I1c0TjrC9Sv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"53f3b16c-37bf-4f67-a064-a63ba2e73892"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["root\n"," |-- longitude: double (nullable = true)\n"," |-- latitude: double (nullable = true)\n"," |-- housing_median_age: double (nullable = true)\n"," |-- total_rooms: double (nullable = true)\n"," |-- total_bedrooms: double (nullable = true)\n"," |-- population: double (nullable = true)\n"," |-- households: double (nullable = true)\n"," |-- median_income: double (nullable = true)\n"," |-- median_house_value: double (nullable = true)\n","\n"]}]},{"cell_type":"code","source":["#Visualizamos la información\n","df_pyspark.show()"],"metadata":{"id":"d5q5LqAcMVM3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b56e8cb0-64e0-45a0-d81c-6683e8f74cf9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n","|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n","+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n","|  -114.31|   34.19|              15.0|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n","|  -114.47|    34.4|              19.0|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n","|  -114.56|   33.69|              17.0|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n","|  -114.57|   33.64|              14.0|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n","|  -114.57|   33.57|              20.0|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n","|  -114.58|   33.63|              29.0|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n","|  -114.58|   33.61|              25.0|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n","|  -114.59|   34.83|              41.0|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n","|  -114.59|   33.61|              34.0|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n","|   -114.6|   34.83|              46.0|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n","|   -114.6|   33.62|              16.0|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|\n","|   -114.6|    33.6|              21.0|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|\n","|  -114.61|   34.84|              48.0|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|\n","|  -114.61|   34.83|              31.0|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|\n","|  -114.63|   32.76|              15.0|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|\n","|  -114.65|   34.89|              17.0|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|\n","|  -114.65|    33.6|              28.0|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|\n","|  -114.65|   32.79|              21.0|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|\n","|  -114.66|   32.74|              17.0|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|\n","|  -114.67|   33.92|              17.0|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|\n","+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["En caso de querer cambiar el tipo de dato de alguna columna lo podemos hacer con las funciones *withColumn()* y *cast()*."],"metadata":{"id":"WSz7YI4wMscN"}},{"cell_type":"code","source":["from pyspark.sql.functions import column\n","df_pyspark=df_pyspark.withColumn(\"housing_median_age\",column(\"housing_median_age\").cast(\"int\"))"],"metadata":{"id":"XWt7j0x4MslB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Con el atributo *dtypes* podemos saber el tipo de dato por columna"],"metadata":{"id":"_Oubrma8MEU-"}},{"cell_type":"code","source":["df_pyspark.dtypes"],"metadata":{"id":"5QJEKDVHDHrE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"06aead40-e7a1-4113-ca40-fa8a64756a85"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('longitude', 'double'),\n"," ('latitude', 'double'),\n"," ('housing_median_age', 'int'),\n"," ('total_rooms', 'double'),\n"," ('total_bedrooms', 'double'),\n"," ('population', 'double'),\n"," ('households', 'double'),\n"," ('median_income', 'double'),\n"," ('median_house_value', 'double')]"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","source":["Si queremos saber el nombre de las columnas utilizamos el atributo *columns*"],"metadata":{"id":"ghry7pbYN43p"}},{"cell_type":"code","source":["df_pyspark.columns"],"metadata":{"id":"-RjGvsq_DT4k","colab":{"base_uri":"https://localhost:8080/"},"outputId":"070f6eda-57b3-4813-90a4-0cf77fc0556c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['longitude',\n"," 'latitude',\n"," 'housing_median_age',\n"," 'total_rooms',\n"," 'total_bedrooms',\n"," 'population',\n"," 'households',\n"," 'median_income',\n"," 'median_house_value']"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","source":["También, se puede seleccionar todos los datos de una columna en particular con la función *select()*."],"metadata":{"id":"YdcYuuXAOBr3"}},{"cell_type":"code","source":["df_pyspark.select('total_rooms').show()"],"metadata":{"id":"9k3Qp6F9DWVP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9e53e2c5-368d-485d-ca99-23aa32705662"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+\n","|total_rooms|\n","+-----------+\n","|     5612.0|\n","|     7650.0|\n","|      720.0|\n","|     1501.0|\n","|     1454.0|\n","|     1387.0|\n","|     2907.0|\n","|      812.0|\n","|     4789.0|\n","|     1497.0|\n","|     3741.0|\n","|     1988.0|\n","|     1291.0|\n","|     2478.0|\n","|     1448.0|\n","|     2556.0|\n","|     1678.0|\n","|       44.0|\n","|     1388.0|\n","|       97.0|\n","+-----------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["O en caso de querer seleccionar varias columnas tambien se puede lograr enviando una lista con el nombre de las columnas como parámetro."],"metadata":{"id":"q5T8sf9yOUxs"}},{"cell_type":"code","source":["df_pyspark.select(['total_rooms', 'total_bedrooms', 'median_income']).show()"],"metadata":{"id":"_JpH1i60DZVk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"28d87877-b71f-407e-a9e3-1d4c078cab16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+--------------+-------------+\n","|total_rooms|total_bedrooms|median_income|\n","+-----------+--------------+-------------+\n","|     5612.0|        1283.0|       1.4936|\n","|     7650.0|        1901.0|         1.82|\n","|      720.0|         174.0|       1.6509|\n","|     1501.0|         337.0|       3.1917|\n","|     1454.0|         326.0|        1.925|\n","|     1387.0|         236.0|       3.3438|\n","|     2907.0|         680.0|       2.6768|\n","|      812.0|         168.0|       1.7083|\n","|     4789.0|        1175.0|       2.1782|\n","|     1497.0|         309.0|       2.1908|\n","|     3741.0|         801.0|       2.6797|\n","|     1988.0|         483.0|        1.625|\n","|     1291.0|         248.0|       2.1571|\n","|     2478.0|         464.0|        3.212|\n","|     1448.0|         378.0|       0.8585|\n","|     2556.0|         587.0|       1.6991|\n","|     1678.0|         322.0|       2.9653|\n","|       44.0|          33.0|       0.8571|\n","|     1388.0|         386.0|       1.2049|\n","|       97.0|          24.0|       1.2656|\n","+-----------+--------------+-------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["Si queremos saber algunas medidas de tendencia central de los datos para los análisis estadísticos se puede utilizar la función *describe()* similar a Pandas."],"metadata":{"id":"y3KgSo5MOg6f"}},{"cell_type":"code","source":["df_pyspark.describe().show()"],"metadata":{"id":"xfKnLrhzDbua","colab":{"base_uri":"https://localhost:8080/"},"outputId":"154a5fc3-ffd4-4f99-fbc5-95fc89ea8252"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n","|summary|          longitude|          latitude|housing_median_age|      total_rooms|   total_bedrooms|        population|       households|     median_income|median_house_value|\n","+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n","|  count|              17000|             17000|             17000|            17000|            17000|             17000|            17000|             17000|             17000|\n","|   mean|-119.56210823529375|  35.6252247058827| 28.58935294117647|2643.664411764706|539.4108235294118|1429.5739411764705|501.2219411764706| 3.883578100000021|207300.91235294117|\n","| stddev| 2.0051664084260357|2.1373397946570867|12.586936981660406|2179.947071452777|421.4994515798648| 1147.852959159527|384.5208408559016|1.9081565183791036|115983.76438720895|\n","|    min|            -124.35|             32.54|                 1|              2.0|              1.0|               3.0|              1.0|            0.4999|           14999.0|\n","|    max|            -114.31|             41.95|                52|          37937.0|           6445.0|           35682.0|           6082.0|           15.0001|          500001.0|\n","+-------+-------------------+------------------+------------------+-----------------+-----------------+------------------+-----------------+------------------+------------------+\n","\n"]}]},{"cell_type":"markdown","source":["De igual manera se pueden agregar columnas directamente al DataFrame si se requiere."],"metadata":{"id":"eE5gL9snPdsE"}},{"cell_type":"code","source":["df_pyspark = df_pyspark.withColumn('Updated_medianhousevalue', df_pyspark['median_house_value']*2)\n","df_pyspark.show()"],"metadata":{"id":"t38O8t0cDfY3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b28be125-7743-4f62-f471-393eea8be55d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------------------------+\n","|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|Updated_medianhousevalue|\n","+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------------------------+\n","|  -114.31|   34.19|                15|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|                133800.0|\n","|  -114.47|    34.4|                19|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|                160200.0|\n","|  -114.56|   33.69|                17|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|                171400.0|\n","|  -114.57|   33.64|                14|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|                146800.0|\n","|  -114.57|   33.57|                20|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|                131000.0|\n","|  -114.58|   33.63|                29|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|                148000.0|\n","|  -114.58|   33.61|                25|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|                164800.0|\n","|  -114.59|   34.83|                41|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|                 97000.0|\n","|  -114.59|   33.61|                34|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|                116800.0|\n","|   -114.6|   34.83|                46|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|                 96200.0|\n","|   -114.6|   33.62|                16|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|                173000.0|\n","|   -114.6|    33.6|                21|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|                124000.0|\n","|  -114.61|   34.84|                48|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|                 97200.0|\n","|  -114.61|   34.83|                31|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|                140800.0|\n","|  -114.63|   32.76|                15|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|                 90000.0|\n","|  -114.65|   34.89|                17|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|                138200.0|\n","|  -114.65|    33.6|                28|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|                189800.0|\n","|  -114.65|   32.79|                21|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|                 50000.0|\n","|  -114.66|   32.74|                17|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|                 88000.0|\n","|  -114.67|   33.92|                17|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|                 55000.0|\n","+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+------------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["De igual forma se pueden eliminar con la función *drop()*"],"metadata":{"id":"VHB46MbDPnmZ"}},{"cell_type":"code","source":["df_pyspark.drop('Updated_medianhousevalue').show()"],"metadata":{"id":"F5Vp00etD_LX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e6c9d2f3-9e69-4771-fcf8-e38b3f870f30"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n","|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|\n","+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n","|  -114.31|   34.19|                15|     5612.0|        1283.0|    1015.0|     472.0|       1.4936|           66900.0|\n","|  -114.47|    34.4|                19|     7650.0|        1901.0|    1129.0|     463.0|         1.82|           80100.0|\n","|  -114.56|   33.69|                17|      720.0|         174.0|     333.0|     117.0|       1.6509|           85700.0|\n","|  -114.57|   33.64|                14|     1501.0|         337.0|     515.0|     226.0|       3.1917|           73400.0|\n","|  -114.57|   33.57|                20|     1454.0|         326.0|     624.0|     262.0|        1.925|           65500.0|\n","|  -114.58|   33.63|                29|     1387.0|         236.0|     671.0|     239.0|       3.3438|           74000.0|\n","|  -114.58|   33.61|                25|     2907.0|         680.0|    1841.0|     633.0|       2.6768|           82400.0|\n","|  -114.59|   34.83|                41|      812.0|         168.0|     375.0|     158.0|       1.7083|           48500.0|\n","|  -114.59|   33.61|                34|     4789.0|        1175.0|    3134.0|    1056.0|       2.1782|           58400.0|\n","|   -114.6|   34.83|                46|     1497.0|         309.0|     787.0|     271.0|       2.1908|           48100.0|\n","|   -114.6|   33.62|                16|     3741.0|         801.0|    2434.0|     824.0|       2.6797|           86500.0|\n","|   -114.6|    33.6|                21|     1988.0|         483.0|    1182.0|     437.0|        1.625|           62000.0|\n","|  -114.61|   34.84|                48|     1291.0|         248.0|     580.0|     211.0|       2.1571|           48600.0|\n","|  -114.61|   34.83|                31|     2478.0|         464.0|    1346.0|     479.0|        3.212|           70400.0|\n","|  -114.63|   32.76|                15|     1448.0|         378.0|     949.0|     300.0|       0.8585|           45000.0|\n","|  -114.65|   34.89|                17|     2556.0|         587.0|    1005.0|     401.0|       1.6991|           69100.0|\n","|  -114.65|    33.6|                28|     1678.0|         322.0|     666.0|     256.0|       2.9653|           94900.0|\n","|  -114.65|   32.79|                21|       44.0|          33.0|      64.0|      27.0|       0.8571|           25000.0|\n","|  -114.66|   32.74|                17|     1388.0|         386.0|     775.0|     320.0|       1.2049|           44000.0|\n","|  -114.67|   33.92|                17|       97.0|          24.0|      29.0|      15.0|       1.2656|           27500.0|\n","+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+\n","only showing top 20 rows\n","\n"]}]},{"cell_type":"markdown","source":["# Tutorial 4: Agregación y agrupamientos\n","\n","Agrupar los datos es una de las habilidades más esenciales cuando trabajamos con Big Data dado que estamos tratando con una gran cantidad de datos y si no somos capaces de segmentar esos datos, entonces será mucho más difícil analizarlos y usarlos para obtener información relevante\n","\n","La regla de oro es recordar que la función *groupBy()* y la función de agregación van de la mano, es decir, no podemos usar groupBy sin la función agregada como SUM, COUNT, AVG, MAX, MIN, etc."],"metadata":{"id":"cYc2mWGlPxFH"}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","\n","spark_aggregate = SparkSession.builder.appName('Aggregate and GroupBy').getOrCreate()\n","spark_aggregate"],"metadata":{"id":"pCMVYeyoT0dq","colab":{"base_uri":"https://localhost:8080/","height":219},"outputId":"7b3478cd-4cee-4fb1-ee02-65bea6db3569"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x7f2405a80310>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://a9cb84e4df70:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.2.2</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySpark_prueba1</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":57}]},{"cell_type":"code","source":["spark_aggregate_data = spark_aggregate.read.csv('part4.csv', header = True, inferSchema = True)\n","spark_aggregate_data.show()"],"metadata":{"id":"L8YpcNuaTtUQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"627786c4-e606-47db-c59e-3a942c977e19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+------------+------+\n","|  Name|  Departmens|salary|\n","+------+------------+------+\n","|Oliver|Data Science| 10000|\n","|Oliver|         IOT|  5000|\n","| Johny|    Big Data|  4000|\n","|Oliver|    Big Data|  4000|\n","| Johny|Data Science|  3000|\n","|Mathew|Data Science| 20000|\n","|Mathew|         IOT| 10000|\n","|Mathew|    Big Data|  5000|\n","| Jacob|Data Science| 10000|\n","| Jacob|    Big Data|  2000|\n","+------+------------+------+\n","\n"]}]},{"cell_type":"markdown","source":["Si llegamos a ejecutar unicamente la función *groupBy()* la respuesta será la ubicación de los datos agrupados lo cual no es relevante"],"metadata":{"id":"j74wnJlET8Gk"}},{"cell_type":"code","source":["spark_aggregate_data.groupBy('Name')"],"metadata":{"id":"R9mnirSyS6O5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3a5df15b-7ddf-4bd3-fa13-272f03e8c820"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.group.GroupedData at 0x7f2402860210>"]},"metadata":{},"execution_count":59}]},{"cell_type":"markdown","source":["## Funciones de agregación\n","\n","Algunas de las funciones más comunes son:\n","\n","\n","\n","*   AVG: devuelve el conjunto de resultados agrupando la columna según el promedio del conjunto de valores.\n","*   COUNT: devolverá el número total de conjuntos de valores en una columna particular correspondiente a la función groupBy.\n","*   MIN: devuelve el valor mínimo o más pequeño entre todo el conjunto de valores en toda la fila.\n","*   MAX: el funcionamiento y el enfoque de usar la función agregada MAX es el mismo que la función agregada MIN, solo que la principal diferencia es que devolverá el valor máximo entre el conjunto de valores en la fila.\n","*   SUM: devolverá la suma de todos los valores numéricos correspondientes a la columna agrupada\n","\n"],"metadata":{"id":"AAlB-sLiUZGS"}},{"cell_type":"markdown","source":["Si ejecutamos la función de agrupamiento y agregación el resultado será la descripción del DataFrame por lo que si queremos visualizar la información hay que utilizar la función *show()*."],"metadata":{"id":"KGaco-YtWYNH"}},{"cell_type":"code","source":["spark_aggregate_data.groupBy('Name').sum()"],"metadata":{"id":"y-35ZH9tVBHq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c44ad39-eccb-44a3-a5bd-d2e181a7d411"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[Name: string, sum(salary): bigint]"]},"metadata":{},"execution_count":60}]},{"cell_type":"markdown","source":["Ejemplo: Conocer la cantidad de dinero total que le pago la compañia a cada empleado agrupando por nombre"],"metadata":{"id":"q54ThS92XAqX"}},{"cell_type":"code","source":["spark_aggregate_data.groupBy('Name').sum().show()"],"metadata":{"id":"AHDQqxfGW0PD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7dd380e5-091c-4e26-ae10-6d7079e813aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+-----------+\n","|  Name|sum(salary)|\n","+------+-----------+\n","| Jacob|      12000|\n","| Johny|       7000|\n","|Mathew|      35000|\n","|Oliver|      19000|\n","+------+-----------+\n","\n"]}]},{"cell_type":"markdown","source":["Ejemplo: Conocer la cantidad de dinero total que pago cada departamento a sus empleados"],"metadata":{"id":"qyyW7WWZXHx4"}},{"cell_type":"code","source":["spark_aggregate_data.groupBy('Departmens').sum().show()"],"metadata":{"id":"c5st2YW3XPIS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3cfa35ee-60e2-4ce1-e77e-bf0ff61fb86a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+-----------+\n","|  Departmens|sum(salary)|\n","+------------+-----------+\n","|         IOT|      15000|\n","|    Big Data|      15000|\n","|Data Science|      43000|\n","+------------+-----------+\n","\n"]}]},{"cell_type":"markdown","source":["Ejemplo: Conocer el salario promedio que se le pago a los empleados por departamento"],"metadata":{"id":"3imE2OXvXaIx"}},{"cell_type":"code","source":["spark_aggregate_data.groupBy('Departmens').mean().show()"],"metadata":{"id":"EdtCu_hsXnO5","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ccb58668-2402-4cc2-ec8b-c7b74d4591c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+-----------+\n","|  Departmens|avg(salary)|\n","+------------+-----------+\n","|         IOT|     7500.0|\n","|    Big Data|     3750.0|\n","|Data Science|    10750.0|\n","+------------+-----------+\n","\n"]}]},{"cell_type":"markdown","source":["Ejemplo: Saber el número de pagos que recibio cada empleado"],"metadata":{"id":"MlhwGhpkXylB"}},{"cell_type":"code","source":["spark_aggregate_data.groupBy(['Name']).count().show()"],"metadata":{"id":"oEowM03EXywJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c9770cb-5c84-4e74-fdad-893c49a4ff60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+------+-----+\n","|  Name|count|\n","+------+-----+\n","| Jacob|    2|\n","| Johny|    2|\n","|Mathew|    3|\n","|Oliver|    3|\n","+------+-----+\n","\n"]}]}]}